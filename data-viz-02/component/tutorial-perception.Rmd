---
title: "Perception tutorial"
author: "Steve Simon"
date: "2017-09-03"
output: powerpoint_presentation
---

```{r echo=FALSE}
knitr::opts_chunk$set(echo = FALSE)
source("../../common-files/setup.R")
```

### Perception, introductory tutorial
+ Visual tasks
+ Hierarchy of perception



### Perception, A framework for graph perception

![Part of first page from Simkin and Hastie journal article](../images/graph-perception.png)

<div class="notes">

Much of the work on the psychology of perception that I will be discussing next is drawn from this 1987 article by Simkin and Hastie.

</div>



### Perception, Which is better? A bar chart...

```{r bar-chart}
n <- c(49, 124, 55, 26)
fn <- initiate_image()
marital_status <- data.frame(
  class=c("Divorced/Separated", "Married", "Single/Never married", "Widowed"),
  n=n,
  prop=round(100*n/sum(n), 1)
)
ggplot(marital_status, aes(x=class, y=prop)) +
  geom_col()
finalize_image()
```

![Bar chart](../images/`r fn`.png)

### Perception, ... or a pie chart

```{r pie-chart}
fn <- initiate_image()
ggplot(marital_status, aes(x = "", y = prop, fill = class)) +
  geom_col() +
  coord_polar("y", start = 0) +
  theme_void()
finalize_image()
```

![Pie chart](../images/`r fn`.png)

### Perception, Answer. It depends.
+ What question are you trying to answer?
  + What proportion of the patients are single?
  + Are there more single or divorced patients?
  
<div class="notes">

The answer really depends on what question you are asking. There are a variety of questions that you might ask. Two are illustrated above.

You can run an experiment (people have done this) where randomize and show half of them a bar chart and half of them a pie chart. Then you ask a question, like one of the questions above. Then you note the speed and accuracy of the response. Depending on the question, sometimes pie charts give faster and more accurate answers. Sometimes bar charts give faster and more accurate answers. It turns out that the results match up nicely with what we know about the psychology of perception.

</div>

### Perception, Visual processing (1 of 3)
+ Projection
  + Shifting an object in a horizontal or vertical direction to make a comparison
+ Superimposition
  + Shifting in other directions (e.g., diagonal shifts, rotation) in order to make a comparison
  + Much harder than projection


### Perception, Projection (first yellow bar versus last yellow bar)

![Stacked bar chart of crop yields](../images/crop-yield-bar-chart-position.png)

<div class="notes">

The position means the vertical or horizontal location. Does the first yellow bar in 1931 (Glabron seeds planted in Wasica) extend further to the right than the last yellow bar (Wisconsin No. 38 seeds planted in Wasica)?

</div>

### Perception, Superimposition (first green bar versus last blue bar)

![Stacked bar chart of crop yields](../images/crop-yield-bar-chart-length.png)

<div class="notes">

The length means either the width or the height. Does the first green bar in 1931 (Glabron seeds planted in University Farm) extend further to the right than the last yellow bar (Wisconsin No. 38 seeds planted in Crookston)?

</div>

### Perception, Visual processing (2 of 3)
+ Scanning
  + Quantifying distance throug the use of a mental tape measure
  + Shorter distances are easier
+ Anchoring
  + Implicit or explicit development of reference points
  + Assists with scanning
  
### Perception, Scanning

```{r scanning}
png("../images/simon_fuel_gauge1.png", width=240, height=480)
df <- data.frame(pct=c(35, 65
                       ), x=factor(rep(1, 2)), z=factor(1:2))
ggplot(df, aes(y=pct, x=x, fill=z)) +
  geom_col(position="stack") +
  theme(legend.position="none") +
  scale_x_discrete(name=NULL, breaks=NULL) +
  scale_y_continuous(name=NULL, breaks=c(0, 100), minor_breaks=NULL, labels=c("Empty", "Full")) +
  scale_fill_manual(values=c("white", "black")) +
  theme(axis.text.y  = element_text(size=24))
quiet <- dev.off()
```

![Image of a fuel gauge, 65% full](../images/simon_fuel_gauge1.png)
  
<div class="notes">

To understand scanning, think of a gas gauge. Usually it is a semicircular dial, but let's set up the gas gauge as a rectangle. If the level is at the top, you have a full tank. If the level is at the bottom, you have an empty tank. This gauge shows a tank that is 65% full. Trust me, I drew the gauge. It is at 65%. Now how would you estimate the gas level?

You would take a mental tape measure, starting at the bottom and measure up to where the black box ends.

Now if you were smart, you'd start at the top and scan downwards. Less distance means that you can do this faster and more accurately.

Now if you were Albert Einstein, you'd split the gauge at the halfway point and measure from the halfway point to the top of the black box. Actually, there's a little of Albert Einstein in all of us. That halfway point is something that all of us do subconciously. You did, because you recognized almost immediately that the tank was more than half full.

</div>

### Perception, Assisting scanning with anchors
  
```{r scanning-with-anchors}
png("../images/simon_fuel_gauge2.png", width=240, height=480)
df <- data.frame(pct=c(35, 65
                       ), x=factor(rep(1, 2)), z=factor(1:2))
ggplot(df, aes(y=pct, x=x, fill=z)) +
  geom_col(position="stack") +
  theme(legend.position="none") +
  scale_x_discrete(name=NULL, breaks=NULL) +
  scale_y_continuous(name=NULL, 
    breaks=c(0, 25, 50, 75, 100), minor_breaks=NULL, 
    labels=c("Empty", "1/4", "Half", "3/4", "Full")) +
  scale_fill_manual(values=c("white", "black")) +
  theme(axis.text.y  = element_text(size=24))
quiet <- dev.off()
```

![Image of a fuel gauge, anchors at 1/4, half, 3/4](../images/simon_fuel_gauge2.png)

<div class="notes">

Here's the same gas gauge, still at 65% full, but now we have added anchors at 1/4, half, and 3/4. You can read this gauge faster and more accurately, because you can scane from half up to 65% or from 3/4 down to 65%.

</div>

### Perception, Visual processing (3 of 3)
+ Visually simple tasks
  + Position
  + Length
  + Angle/slope
+ Visually demanding tasks
  + Area
  + Volume
  + Density/Saturation/Hue
  
<div class="notes">

There are a variety of perceptual tasks that you use when making comparisons within an image. These are arranged on this slide roughly in order of difficulty, with the easiest tasks at the top.

</div>

### Perception, Position (first yellow bar versus last yellow bar)

![Stacked bar chart of crop yields](../images/crop-yield-bar-chart-position.png)

<div class="notes">

The comparison of the two yellow bars is a comparison of position. Which yellow bar extends further to the right?

</div>

### Perception, Length (first green bar versus last blue bar)

![Stacked bar chart of crop yields](../images/crop-yield-bar-chart-length.png)

<div class="notes">

The comparison of the green and blue bars is a length comparison. The two bars start at different spots, so the position can't help you.

Length is harder to judge than position, because it involves a superimposition rather than a projection.

</div>

### Perception, Angle/slope (first month decline versus last month decline)

![Sales trend shown with a line graph](../images/sales-trend.png)

<div class="notes">

This graph shows sales trends over a twelve month span. If you want to assess whether the first month decline (the dip in sales between January and February) was worse than the last month decline (the dip in sales between November and December), you would probably do this by judging the angle of the first line segment to the angle of the second line segment. This is not quite as easy as a position or length judgement, but it isn't too bad either.

</div>

### Perception, Area

![Three ellipses](../images/ellipses.png)

### Perception, Area

![Bubble plot](../images/investment-risk.png)

<div class="notes">

This graph shows exposure and margin trends on the x and y axes. Larger values are worse on both axes. The size of the bubble is the size of the company (annual sales). There is some ambiguity here--is size measured in terms of diameter or in terms of area. Which is bigger, the brown circle (Metro) or the dark blue circle (Tesco)?

</div>

### Perception, Volume

![Ellipsoid plot](../images/rgl_cda_ellipsoids.png)

### Perception, Color

![Weather map of annual snowfall](../images/btv_snow_average.png)

<div class="notes">

What city gets more snowfall, Remington, in the southwester corner of the state, or Newport, in the northeast corner of the state?

</div>

### Perception, Adding depth (1/4)

![THree dimensional bar chart](../images/bars-3d-1.png)

<div class="notes">

Some sotware packages allow you to add some depth to your pie chart. This can catch your eye, at first, but almost all experts hate this approach. The most common complaint is that the three dimensional effects make a graph worse.

Worse means that it slows you down and it decreases the accuracy of your response. So here's a question. What percentage of your sample is single/never married? THe three dimensional effects slow you down. So for this three dimensional bar chart, do you measure the height of the single/never married bar by projecting the front of the bar to the axis on the left or by projecting the back of the bar? Actually, you need to first project to the back "wall" because the bars are placed a small distance in front.

</div>

### Perception, Adding depth (2/4)

![Projection lines for a three dimensional bar chart](../images/bars-3d-2.png)

<div class="notes">

Once you realize that you need to project to the back wall, you have to do this accurately. Notice that it is not a simple horizontal or vertical projection. Instead you have to do a couple of superimpositions, shifts at a 45 degree angle. You can do this, but it degrades your accuracy.

</div>

### Perception, Adding depth (3/4)

![Three dimensional pie chart](../images/pie-3d-1.png)

### Perception, Adding depth (4/4)

```{r pie-3d-2}
fn <- initiate_image()
theta <- seq(0, 2*pi, length=200)
fn <- initiate_image()
plot(-1:1, -1:1, axes=FALSE, type="n", xlab=" ", ylab=" ")
lines(sin(theta), 0.5*cos(theta))
lines(c( 1,  1), c( 0, -0.3))
lines(c(-1, -1), c( 0, -0.3))
lines(sin(theta[51:150]), 0.5*cos(theta[51:150])-0.3)
lines(sin(theta[c( 25, 125, 125)]), 0.5*cos(theta[c( 25, 125, 125)])-c(0,0,0.3))
lines(sin(theta[c(175,  75,  75)]), 0.5*cos(theta[c(175,  75,  75)])-c(0,0,0.3))
finalize_image()
```

![Three dimensional pie chart split into four equal pieces](../images/`r fn`.png)

<div class="notes">

There are several issues with the three dimensional pie chart, and you can see this best when you split this pie chart into four equal pieces. Notice that the angles are no longer 90 degrees because the perspective view distorts the angles. So you lose the big advantage (and possibly the only advantage) of the pie chart, the ability to divide it easily into four pieces.

Also notice that the wedge in the foreground looks bigger than the wedge in the background, because you can see the side of the foreground wedge, but you can't see the side of the background wedge.

</div>

### Perception, review
+ Visual tasks
+ Hierarchy of perception

